{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1mL30VypqJIiFD6KTmNcCp-bJdRJVDzXl",
      "authorship_tag": "ABX9TyMuJxGU6nvr25h1LTM+0pAL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anju1982/Anju/blob/main/Transferlearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeqG9mmy33Jc"
      },
      "outputs": [],
      "source": [
        "#transfer learning\n",
        "# Retrieve the Xception model from Keras\n",
        "#view the entire model  \n",
        "Xception_model = keras.applications.Xception()\n",
        "\n",
        "tf.keras.utils.plot_model(#before using this model we want to know what the Xception model is\n",
        "    Xception_model,\n",
        "    to_file='Xmodel.png',\n",
        "    show_shapes=False,\n",
        "    show_layer_names=False,\n",
        "    rankdir='LR',\n",
        "    expand_nested=False,\n",
        "    dpi=96\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "from tensorflow import keras\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import glob\n",
        "import PIL\n",
        "from PIL import Image\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0g3LYB99mHT",
        "outputId": "6e79f801-d2a1-418d-f8e8-80e40c4cd54a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " ! unzip '/content/drive/MyDrive/MLand DL/Flower_dataset.zip' -d '/content/drive/MyDrive/ML and DL'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUdB6PHY9y4D",
        "outputId": "09adef3c-5e09-4b4c-f6a7-dbbe2ec69be6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/drive/MyDrive/MLand DL/Flower_dataset.zip, /content/drive/MyDrive/MLand DL/Flower_dataset.zip.zip or /content/drive/MyDrive/MLand DL/Flower_dataset.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U2-w0YfjThLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgFiles = glob.glob(\"/content/drive/MyDrive/mlanddl/Flower_dataset/*/*.jpg\") #navigate through sub-folders, parses them and store in a list\n",
        "for items in imgFiles[:8]: #imgFiles is a list of strings, each string corresponds to the file path \n",
        "  print(items)"
      ],
      "metadata": {
        "id": "NSu3nRl4_kID"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(imgFiles))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rrah6avr_pP6",
        "outputId": "9ba6b799-d52b-4321-a6fc-8a0940af847b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for fName in imgFiles:\n",
        "  \n",
        "  # Prepare the dataset and populate X and y\n",
        "  X_i = Image.open(fName) # tiny_FR/sunflower/1715303025_e7065327e2.jpg (500, 333)\n",
        "  X_i = X_i.resize((299,299)) # To make them approriate to Xception model when using Transfer Learning \n",
        "  X_i = np.array(X_i) / 255.0 # Normalize to range 0.0 to 1.0 \n",
        "  X.append(X_i)\n",
        "\n",
        "  label = fName.split(\"/\") # ['tiny_FR', 'sunflower', '1715303025_e7065327e2.jpg'], list containing substrings\n",
        "  y_i = label[-2] # 'sunflower'\n",
        " \n",
        "  y.append(y_i)\n",
        "\n",
        "#processed all  image files and corresponding intensity values and labels stored in X and y respectively "
      ],
      "metadata": {
        "id": "sn1GXQam_wFU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(set(y)) # python function that lists unique values in the list. # these are string labels\n",
        "\n",
        "# but the network can only deal with numeric data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGgl3mZX_3Wb",
        "outputId": "cb620ab2-9e94-4304-881f-0552d842b536"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "set()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "lEncoder = LabelEncoder()\n",
        "y = lEncoder.fit_transform(y)\n",
        "print(set(y))\n",
        "\n",
        "print(lEncoder.classes_) #classes_ is a member variable in the class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIC_40F9_9cS",
        "outputId": "e67212a9-8a71-4763-d484-b4facf2e166d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "set()\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtNrTXlnACsi",
        "outputId": "8f8f67bd-11ad-4093-907f-f5c23db2842a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0,)\n",
            "(0,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
        "                                                    stratify=y, random_state=42)\n",
        "\n",
        "print(\"X_train_shape: {}\".format(X_train.shape))\n",
        "print(\"X_test_shape: {}\".format(X_test.shape))\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "kPdgJ5-XAVfy",
        "outputId": "12103362-4619-4e1c-be3c-01ffb3f195dc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-b90a11755698>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n\u001b[0m\u001b[1;32m      4\u001b[0m                                                     stratify=y, random_state=42)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2421\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2097\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2098\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2099\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Keras Applications\n",
        "#https://keras.io/api/applications/\n",
        "#Keras Applications\n",
        "# Retrieve the Xception model from Keras\n",
        "#view the entire model  \n",
        "Xception_model = keras.applications.Xception()\n",
        "\n",
        "tf.keras.utils.plot_model(\n",
        "    Xception_model,\n",
        "    to_file='Xmodel.png',\n",
        "    show_shapes=False,\n",
        "    show_layer_names=False,\n",
        "    rankdir='LR',\n",
        "    expand_nested=False,\n",
        "    dpi=96\n",
        ")"
      ],
      "metadata": {
        "id": "01Q5C5YgTqzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For transfer learning\n",
        "include_top=False\n",
        "weights = 'imagenet\n",
        "##https://keras.io/api/applications/\n"
      ],
      "metadata": {
        "id": "ByKHEzyoUFpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take only the feature extractor part\n",
        "\n",
        "base_model = keras.applications.Xception(weights='imagenet', \n",
        "                                                  include_top=False)\n",
        "\n",
        "# Visualize the extractor part for transfer learning\n",
        "\n",
        "tf.keras.utils.plot_model(\n",
        "    base_model,\n",
        "    to_file='baseModel.png',\n",
        "    show_shapes=False,\n",
        "    show_layer_names=False,\n",
        "    rankdir='LR',\n",
        "    expand_nested=False,\n",
        "    dpi=96\n",
        ")"
      ],
      "metadata": {
        "id": "JgpUROTFUWOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the weights/parameters of fetaure extractor non-trainable\n",
        "# Freeze the weights - will not be updated during backpropagation\n",
        "for layer in base_model.layers:\n",
        "  layer.trainabe = False"
      ],
      "metadata": {
        "id": "MuFFIYc5UblY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add classifier part\n",
        "Global Average Pooling - 2D\n",
        "Output layer (5 units (because 5-class classificaiton problem)\n",
        "# Adding classifier\n",
        "#Inspect how flattening is made in the pretrained model. In Xception, they use GAP\n",
        "global_pool = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "\n",
        "output_ = keras.layers.Dense(units=5, activation='softmax')(global_pool)\n",
        "\n",
        "model_TL = keras.models.Model(inputs=[base_model.input], outputs=[output_])\n",
        "\n",
        "# Visualize the complete model\n",
        "tf.keras.utils.plot_model(\n",
        "    model_TL,\n",
        "    to_file='Model_TL.png',\n",
        "    show_shapes=False,\n",
        "    show_layer_names=False,\n",
        "    rankdir='LR',\n",
        "    expand_nested=False,\n",
        "    dpi=96\n",
        ")\n",
        "     "
      ],
      "metadata": {
        "id": "kKDn6oglUjgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Compile and train the model\n",
        "Save the best weights while training\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint\n",
        "model_TL.compile(loss='sparse_categorical_crossentropy', \n",
        "                 optimizer='adam', \n",
        "                 metrics=['accuracy'])\n",
        "#introduce callbacks to save the best model\n",
        "\n",
        "\n",
        "callbacks_TL = [            \n",
        "             keras.callbacks.ModelCheckpoint(\"bestTL.h5\",\n",
        "                                             monitor='val_accuracy',verbose=1,\n",
        "                                             save_weights_only=True,\n",
        "                                             save_best_only=True)]\n",
        "\n",
        "\n",
        "history_TL = model_TL.fit(x = X_train_std, y = y_train, epochs=50, \n",
        "                          validation_split=0.1, batch_size=16, callbacks=callbacks_TL)\n",
        "     \n",
        "\n",
        "keys = ['accuracy', 'val_accuracy']\n",
        "progress = {k:v for k,v in history_TL.history.items() if k in keys}\n",
        "\n",
        "import pandas as pd\n",
        "pd.DataFrame(progress).plot()\n",
        "\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "     \n"
      ],
      "metadata": {
        "id": "C64Yd5y1UtSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the model \n",
        "\n",
        "testLoss_TL, testAccuracy_TL = model_TL.evaluate(x = X_test_std, y = y_test)\n",
        "print(\"Test-loss: %f, Test-accuracy: %f\" % (testLoss_TL, testAccuracy_TL))"
      ],
      "metadata": {
        "id": "BwxA3-keU8wJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Update the model with best weights\n",
        "These weights may be from an intermediate epoch"
      ],
      "metadata": {
        "id": "ZlxYEUB2VFWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_TL.load_weights(\"bestTL.h5\")\n",
        "\n",
        "testLoss_TL, testAccuracy_TL = model_TL.evaluate(x = X_test_std, y = y_test)\n",
        "\n",
        "print(\"Test-loss: %f, Test-accuracy: %f\" % (testLoss_TL, testAccuracy_TL))"
      ],
      "metadata": {
        "id": "4nlqugt1VKsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the model & dataset(for finetuning)\n",
        "# Saves the best model obtained in drive( if not saved in drive)\n",
        "model_TL.save('/content/drive/MyDrive/Models/01_Xception_TransferLearning_Best_Model.h5')\n",
        "     "
      ],
      "metadata": {
        "id": "UNvt5W7RVPCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import save\n",
        "#.npy is numpy array format \n",
        "save('/content/drive/MyDrive/Models/X_train_std.npy', X_train_std)\n",
        "save('/content/drive/MyDrive/Models/X_test_std.npy', X_test_std)\n",
        "\n",
        "save('/content/drive/MyDrive/Models/y_train.npy', y_train)\n",
        "save('/content/drive/MyDrive/Models/y_test.npy', y_test)\n",
        "     "
      ],
      "metadata": {
        "id": "SY-v8mWqVYDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fine Tuning\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OnTWvz3oWCKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "from tensorflow import keras\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "xHa07kmbWMhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the dataset which is already processed\n",
        "# load numpy array from npy file\n",
        "from numpy import load\n",
        "\n",
        "X_train_std = load('/content/drive/MyDrive/Models/X_train_std.npy')\n",
        "X_test_std = load('/content/drive/MyDrive/Models/X_test_std.npy')\n",
        "\n",
        "y_train = load('/content/drive/MyDrive/Models/y_train.npy')\n",
        "y_test = load('/content/drive/MyDrive/Models/y_test.npy')\n",
        "     "
      ],
      "metadata": {
        "id": "tIAw_Ba8WQoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train_std_shape: {}\".format(X_train_std.shape))\n",
        "print(\"X_test_std_shape: {}\".format(X_test_std.shape))\n",
        "     "
      ],
      "metadata": {
        "id": "dIVYJMzbWZJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved best model\n",
        "\n",
        "model_FineTune = keras.models.load_model('/content/drive/MyDrive/Models/01_Xception_TransferLearning_Best_Model.h5')\n",
        "     "
      ],
      "metadata": {
        "id": "yGSctIvtWebK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_FineTune.summary()\n"
      ],
      "metadata": {
        "id": "5YFhcO6wWiMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_FineTune.layers"
      ],
      "metadata": {
        "id": "0SCiAU17WoZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(model_FineTune.layers)\n",
        "     "
      ],
      "metadata": {
        "id": "E5UJbgIQWskp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune the model from index 60 onwards\n",
        "\n",
        "for layer in model_FineTune.layers[:60]:\n",
        "  layer.trainable = False\n",
        "\n",
        "for layer in model_FineTune.layers[60:]:\n",
        "  layer.trainable = True"
      ],
      "metadata": {
        "id": "haYU7w-lWxFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Compile and train the model\n",
        "Save the best weights while training\n",
        "#model_FineTune.compile(loss='sparse_categorical_crossentropy', \n",
        "                 optimizer='adam', \n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "callbacks_FineTune = [            \n",
        "             keras.callbacks.ModelCheckpoint(\"bestFT.h5\",\n",
        "                                             monitor='val_accuracy',\n",
        "                                             save_weights_only=True,\n",
        "                                             save_best_only=True)\n",
        "]\n",
        "\n",
        "history_FineTune = model_FineTune.fit(x = X_train_std, y = y_train, epochs=50,\n",
        "                                      validation_split=0.1, batch_size=16, callbacks=callbacks_FineTune)"
      ],
      "metadata": {
        "id": "fSVwUmBSW0tJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}